{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb248314",
   "metadata": {},
   "source": [
    "# Movie rating prediction\n",
    "\n",
    "dataset link: https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "Our goal is to train a model to predict if a movie reveiw is a positive or a negative one.\n",
    "Dataset is already splitted 50/50: 12.5k positive reviews and 12.5k negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec68381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/alex/bin/Notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f'Current working directory: {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd36244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from random import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "currdir = Path(os.getcwd())\n",
    "train_folder = currdir / 'aclImdb' / 'train'\n",
    "test_folder = currdir / 'aclImdb' / 'test'\n",
    "\n",
    "def get_data_frame(folder):\n",
    "    '''\n",
    "    Get text files from folder,\n",
    "    clean, shuffle and combine it\n",
    "    and return a pd.DataFrame object.\n",
    "    '''\n",
    "    \n",
    "    def import_files(data_folder):\n",
    "        '''\n",
    "        Return all .txt files in 'data_folder'.\n",
    "        Data_folder - pathlib.Path() object.\n",
    "        '''\n",
    "        files = [\n",
    "            e for e in data_folder.iterdir()\n",
    "            ]\n",
    "        return files\n",
    "\n",
    "    def get_text_from_file(_file):\n",
    "        '''\n",
    "        Return text from file\n",
    "        '''\n",
    "        text = _file.read_text()\n",
    "        return text\n",
    "    \n",
    "    ### getting data from folder\n",
    "    \n",
    "    positives_folder = folder / 'pos'\n",
    "    negatives_folder = folder / 'neg'\n",
    "    \n",
    "    positive_files = import_files(positives_folder)\n",
    "    negative_files = import_files(negatives_folder)\n",
    "\n",
    "    positive = []\n",
    "    negative = []\n",
    "    \n",
    "    for f in positive_files:\n",
    "        text = get_text_from_file(f)\n",
    "        positive.append(text)\n",
    "    \n",
    "    for f in negative_files:\n",
    "        text = get_text_from_file(f)\n",
    "        negative.append(text)\n",
    "    \n",
    "    ### cleaning data\n",
    "    \n",
    "    # removing part of <br > tags\n",
    "    regex2 = re.compile(r'<br\\s')\n",
    "\n",
    "    # than matching only alphabetic characters\n",
    "    regex = re.compile(r'[^a-zA-z\\s]')\n",
    "\n",
    "    # applying\n",
    "    for data_list in [positive, negative]:\n",
    "        for i in range(len(data_list)):\n",
    "            data_list[i] = regex2.sub('', data_list[i])\n",
    "            data_list[i] = regex.sub('', data_list[i])\n",
    "    \n",
    "    ### making a pre-dataset in a list\n",
    "    \n",
    "    ones = [1 for item in positive]\n",
    "    zeros = [0 for item in negative]\n",
    "\n",
    "    positive = list(zip(positive, ones))\n",
    "    negative = list(zip(negative, zeros))\n",
    "\n",
    "    # now each list is a [('<some text>', 1 or 0), ('<some text>'), 1 or 0, ...]\n",
    "    \n",
    "    ### making a pd.DataFrame object\n",
    "\n",
    "    training_set = positive + negative\n",
    "\n",
    "    # shuffling data\n",
    "\n",
    "    shuffle(training_set)\n",
    "\n",
    "    text, label = tuple(zip(*training_set))\n",
    "    \n",
    "    # text and label vars contain correspondent pairs: \n",
    "    # (text, text, text...) and (label, label, label)\n",
    "    \n",
    "    data_frame = pd.DataFrame({'text': text, 'label': label})\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee68a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = get_data_frame(train_folder)\n",
    "test_set = get_data_frame(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3223ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving sets in csv files\n",
    "\n",
    "os.system(\"mkdir 'csv'\")\n",
    "train_set.to_csv('csv/train_set.csv', index=False)\n",
    "test_set.to_csv('csv/test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eedc9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = pd.read_csv('csv/train_set.csv')\n",
    "#test_set = pd.read_csv('csv/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "703cd50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing the sets\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(train_set['text'].values)\n",
    "X_train = vectorizer.transform(train_set['text'].values)\n",
    "X_test = vectorizer.transform(test_set['text'].values)\n",
    "\n",
    "# making np.arrays from labels\n",
    "\n",
    "y_train = np.array(train_set['label'].values)\n",
    "y_test = np.array(test_set['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b1ef8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ***\n",
      "SGDClassifier:\n",
      "Train score: 0.94 ; Test score: 0.884\n",
      "\n",
      "F1_score: 0.883\n",
      "Accuracy: 0.884\n",
      "Precision: 0.885\n",
      "Recall: 0.882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training model, getting scores\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "def train_and_score(\n",
    "    classifier,\n",
    "    create_instance=True,\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test):\n",
    "    '''\n",
    "    Train classifier and print out its train/test score\n",
    "    '''\n",
    "    if create_instance:\n",
    "        clf = classifier()\n",
    "    else:\n",
    "        clf = classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accur = round(metrics.accuracy_score(y_test, y_pred), 3)\n",
    "    prec = round(metrics.precision_score(y_test, y_pred), 3)\n",
    "    recall = round(metrics.recall_score(y_test, y_pred), 3)\n",
    "    f1 = round(metrics.f1_score(y_test, y_pred), 3)\n",
    "\n",
    "    print(' ***')\n",
    "    print(f'{classifier.__name__}:\\nTrain score: {round(train_score, 3)} ; Test score: {round(test_score, 3)}\\n')\n",
    "    print(f'F1_score: {f1}\\nAccuracy: {accur}\\nPrecision: {prec}\\nRecall: {recall}\\n')\n",
    "    \n",
    "clf_list = [\n",
    "    dict(classifier=SGDClassifier)\n",
    "# too slow   dict(classifier=svm.SVC(kernel='linear'), create_instance=False)\n",
    "    ]\n",
    "\n",
    "for clf in clf_list:\n",
    "    train_and_score(**clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5444edd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "text1 = '''\n",
    "That was a gorgeous experience and the best way to spend that Friday evening of mine.\n",
    "Actors played brilliant, screenplay seemed a nut in the start but then goes smoothly\n",
    "'''\n",
    "text2 = '''\n",
    "A couldn't say it is a boring staff. In fact, it is just silly and obcure, nothing personal.\n",
    "This and that was rather good, but who can state that all that staff worth a damn?\n",
    "'''\n",
    "\n",
    "text3 = '''\n",
    "I love all his films, but that stuff was a kind of puff. You could expect a sophisticated\n",
    "story, nevertheless your emotions would tell you to disdain complex expectations and to drain\n",
    "your dreams in mustard and mayonaisse. All is good, but the bad stuff can't get itself out.\n",
    "Dear fans, you would be in a weird mess of profanity.\n",
    "'''\n",
    "\n",
    "good = vectorizer.transform([text1])\n",
    "bad = vectorizer.transform([text2])\n",
    "complex_one = (vectorizer.transform([text3]))\n",
    "\n",
    "clf = SGDClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.predict(good))\n",
    "print(clf.predict(bad))\n",
    "print(clf.predict(complex_one))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
